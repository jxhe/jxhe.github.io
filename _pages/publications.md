---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

Below is a list of recent publications that are representative of my current research. A full list is on [Google Scholar](https://scholar.google.com/citations?user=BIFGeoUAAAAJ&hl=en).  
\* denotes co-first authors
<!-- $^\dagger$ denotes corresponding author/main advisor -->

<h2 class="pub-section">Language Agents</h2>
**The Tool Decathlon: Benchmarking Language Agents for Diverse, Realistic, and Long-Horizon Task Execution**  
Junlong Li\*, Wenshuo Zhao\*, Jian Zhao\*, Weihao Zeng\*, Haoze Wu\*, Xiaochen Wang, Rui Ge, Yuxuan Cao, Yuzhen Huang, Wei Liu, Junteng Liu, Zhaochen Su, Yiyang Guo, Fan Zhou, Lueyang Zhang, Juan Michelini, Xingyao Wang, Xiang Yue, Shuyan Zhou, Graham Neubig, *<ins>Junxian He</ins>*  
ICLR 2026. [arxiv](https://arxiv.org/abs/2510.25726) [github](https://github.com/hkust-nlp/toolathlon) [website](https://toolathlon.xyz/)

**WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents**  
Junteng Liu\*, Yunji Li\*, Chi Zhang, Jingyang Li, Aili Chen, Ke Ji, Weiyu Cheng, Zijia Wu, Chengyu Du, Qidi Xu, Jiayuan Song, Zhengmao Zhu, Wenhu Chen, Pengyu Zhao, *<ins>Junxian He</ins>*  
Preprint 2025. [arxiv](https://arxiv.org/abs/2509.06501) [github](https://github.com/hkust-nlp/WebExplorer)

**SWE-RM: Execution-free Feedback For Software Engineering Agents**  
KaShun Shum\*, Binyuan Hui\*, Jiawei Chen, Lei Zhang, X. W., Jiaxi Yang, Yuzhen Huang, Junyang Lin, *<ins>Junxian He</ins>*  
ICLR 2026. [arxiv](https://www.arxiv.org/abs/2512.21919)

**Pushing Test-Time Scaling Limits of Deep Search with Asymmetric Verification**  
Weihao Zeng, Keqing He, Chuqiao Kuang, Xiaoguang Li, *<ins>Junxian He</ins>*  
ICLR 2026. [arxiv](https://arxiv.org/abs/2510.06135)

**AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents**  
Chang Ma\*, Junlei Zhang\*, Zhihao Zhu\*, Cheng Yang\*, Yujiu Yang, Yaohui Jin, Zhenzhong Lan, Lingpeng Kong, *<ins>Junxian He</ins>*  
NeurIPS 2024 (Datasets and Benchmarks Track). <span style="color:red"><i>Oral</i></span> [arxiv](https://arxiv.org/abs/2401.13178) [github](https://github.com/hkust-nlp/AgentBoard)

<h2 class="pub-section">Reinforcement Learning, Self-Improving, Synthetic Data</h2>

**SimpleRL-Zoo: Investigating and Taming Zero Reinforcement Learning for Open Base Models in the Wild**  
Weihao Zeng\*, Yuzhen Huang\*, Qian Liu\*, Wei Liu, Keqing He, Zejun MA, *<ins>Junxian He</ins>*  
COLM 2025. [arxiv](https://arxiv.org/abs/2503.18892) [github](https://github.com/hkust-nlp/simpleRL-reason)

**CodeIO: Condensing Reasoning Patterns via Code Input-Output Prediction**  
Junlong Li, Daya Guo, Dejian Yang, Runxin Xu, Yu Wu, *<ins>Junxian He</ins>*  
ICML 2025. <span style="color:red"><i>Oral</i></span> [arxiv](https://arxiv.org/abs/2502.07316) [github](https://github.com/hkust-nlp/CodeIO)

**Mirage or Method? How Model-Task Alignment Induces Divergent RL Conclusions**  
Haoze Wu\*, Cheng Wang\*, Wenshuo Zhao, *<ins>Junxian He</ins>*  
ICLR 2026. [arxiv](https://arxiv.org/abs/2508.21188) [github](https://github.com/hkust-nlp/model-task-align-rl)

<!-- **SynLogic: Synthesizing Verifiable Reasoning Data at Scale for Learning Logical Reasoning and Beyond**  
Junteng Liu, Yuanxiang Fan, Zhuo Jiang, Han Ding, Yongyi Hu, Chi Zhang, Yiqi Shi, Shitong Weng, Aili Chen, Shiqi Chen, Yunan Huang, Mozhi Zhang, Pengyu Zhao, Junjie Yan, *<ins>Junxian He</ins>*  
NeurIPS 2025. [arxiv](https://arxiv.org/abs/2505.19641) [github](https://github.com/MiniMax-AI/SynLogic) -->


**B-STaR: Monitoring and Balancing Exploration and Exploitation in Self-Taught Reasoners**  
Weihao Zeng\*, Yuzhen Huang\*, Lulu Zhao, Yijun Wang, Zifei Shan, *<ins>Junxian He</ins>*  
ICLR 2025. [arxiv](https://arxiv.org/abs/2412.17256) [github](https://github.com/hkust-nlp/B-STaR)

**DART-Math: Difficulty-Aware Rejection Tuning for Mathematical Problem-Solving**  
Yuxuan Tong, Xiwen Zhang, Rui Wang, Ruidong Wu, *<ins>Junxian He</ins>*   
NeurIPS 2024. [arxiv](https://arxiv.org/abs/2407.13690) [github](https://github.com/hkust-nlp/dart-math)

**What Makes Good Data for Alignment? A Comprehensive Study of Automatic Data Selection in Instruction Tuning**  
Wei Liu\*, Weihao Zeng\*, Keqing He, Yong Jiang, *<ins>Junxian He</ins>*  
ICLR 2024. [arxiv](https://arxiv.org/abs/2312.15685) [github](https://github.com/hkust-nlp/deita)


<h2 class="pub-section">Evaluation</h2>

**Compression Represents Intelligence Linearly**    
Yuzhen Huang\*, Jinghan Zhang\*, Zifei Shan, *<ins>Junxian He</ins>*  
COLM 2024. [arxiv](https://arxiv.org/abs/2404.09937) [code](https://github.com/hkust-nlp/llm-compression-intelligence)

**C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models**  
Yuzhen Huang\*, Yuzhuo Bai\*, Zhihao Zhu, Junlei Zhang, Jinghan Zhang, Tangjun Su, Junteng Liu, Chuancheng Lv, Yikai Zhang, Jiayi Lei, Yao Fu, Maosong Sun, *<ins>Junxian He</ins>*  
NeurIPS 2023 (Datasets and Benchmarks track). [arxiv](https://arxiv.org/abs/2305.08322) [github](https://github.com/hkust-nlp/ceval) [website](https://cevalbenchmark.com) [dataset](https://huggingface.co/datasets/ceval/ceval-exam)

**FELM: Benchmarking Factuality Evaluation of Large Language Models**  
Shiqi Chen, Yiran Zhao, Jinghan Zhang, I-Chun Chern, Siyang Gao, Pengfei Liu, *<ins>Junxian He</ins>*  
NeurIPS 2023 (Datasets and Benchmarks track). [arxiv](https://arxiv.org/abs/2310.00741) [github](https://github.com/hkust-nlp/felm) [website](https://hkust-nlp.github.io/felm/) [dataset](https://huggingface.co/datasets/hkust-nlp/felm)

<h2 class="pub-section">Some Earlier Interesting Works (Post-Training, Synthetic Data, PGMs)</h2>

**Towards a Unified View of Parameter-Efficient Transfer Learning**  
*<ins>Junxian He</ins>*\*, Chunting Zhou*, Xuezhe Ma, Taylor Berg-Kirkpatrick, Graham Neubig   
ICLR 2022. <span style="color:red"><i>Spotlight</i></span> [OpenReview](https://openreview.net/forum?id=0RDcd5Axok) [arxiv](http://arxiv.org/abs/2110.04366) [code](https://github.com/jxhe/unify-parameter-efficient-tuning)

**CTRLsum: Towards Generic Controllable Text Summarization**  
*<ins>Junxian He</ins>*, Wojciech Kryściński, Bryan McCann, Nazneen Rajani, Caiming Xiong  
EMNLP 2022. [arxiv](https://arxiv.org/abs/2012.04281) [code](https://github.com/salesforce/ctrl-sum) [huggingface demo](https://huggingface.co/spaces/akhaliq/ctrl-sum) [streamlit demo](https://share.streamlit.io/jxhe/ctrlsum-demo/ctrlsum_demo.py)

**Revisiting Self-Training for Neural Sequence Generation**  
*<ins>Junxian He</ins>*\*, Jiatao Gu*, Jiajun Shen, Marc'Aurelio Ranzato  
ICLR 2020. [arxiv](https://arxiv.org/abs/1909.13788) [code](https://github.com/jxhe/self-training-text-generation)

**Lagging Inference Networks and Posterior Collapse in Variational Autoencoders**  
*<ins>Junxian He</ins>*, Daniel Spokoyny, Graham Neubig, Taylor Berg-Kirkpatrick  
ICLR 2019. [arxiv](http://arxiv.org/abs/1901.05534) [code](https://github.com/jxhe/vae-lagging-encoder)

**Unsupervised Learning of Syntactic Structure with Invertible Neural Projections**   
*<ins>Junxian He</ins>*, Graham Neubig, Taylor Berg-Kirkpatrick  
EMNLP 2018. [arxiv](https://arxiv.org/abs/1808.09111) [code](https://github.com/jxhe/struct-learning-with-flow)


<!-- **Diving into Self-Evolving Training for Multimodal Reasoning**  
Wei Liu\*, Junlong Li\*, Xiwen Zhang, Fan Zhou, Yu Cheng, *<ins>Junxian He</ins>*  
ICML 2025. [arxiv](https://arxiv.org/abs/2412.17451)  [github](https://github.com/hkust-nlp/mstar)

**Bring Reason to Vision: Understanding Perception and Reasoning through Model Merging**  
Shiqi Chen\*, Jinghan Zhang\*, Tongyao Zhu, Wei Liu, Siyang Gao, Miao Xiong, Manling Li, *<ins>Junxian He</ins>*  
ICML 2025.   -->



<!-- **Predictive Data Selection: The Data That Predicts Is the Data That Teaches**  
Kashun Shum\*, Yuzhen Huang\*, Hongjian Zou, Qi Ding, Yixuan Liao, Xiaoxin Chen, Qian Liu, *<ins>Junxian He</ins>*    
ICML 2025. [arxiv](https://arxiv.org/abs/2503.00808)  [github](https://github.com/hkust-nlp/PreSelect)

**Why Is Spatial Reasoning Hard for VLMs? An Attention Mechanism Perspective on Focus Areas**  
Shiqi Chen, Tongyao Zhu, Ruochen Zhou, Jinghan Zhang, Siyang Gao, Juan Carlos Niebles, Mor Geva, *<ins>Junxian He</ins>*, Jiajun Wu, Manling Li  
ICML 2025. [arxiv](https://arxiv.org/abs/2503.01773) [github](https://github.com/shiqichen17/AdaptVis) -->


<!-- **Non-myopic Generation of Language Models for Reasoning and Planning**  
Chang Ma, Haiteng Zhao, Junlei Zhang, *<ins>Junxian He</ins>*, Lingpeng Kong  
ICLR 2025. [arxiv](https://arxiv.org/abs/2410.17195) -->

<!-- **Diving into Self-Evolving Training for Multimodal Reasoning**  
Wei Liu\*, Junlong Li\*, Xiwen Zhang, Fan Zhou, Yu Cheng, *<ins>Junxian He</ins>*  
Preprint 2024. [arxiv](https://arxiv.org/abs/2412.17451) [github](https://github.com/hkust-nlp/mstar) -->




<!-- 
**Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances Information Seeking in LLMs**  
Zhiyuan Hu, Chumin Liu, Xidong Feng, Yilun Zhao, See-Kiong Ng, Anh Tuan Luu, *<ins>Junxian He</ins>*, Pang Wei Koh, Bryan Hooi  
NeurIPS 2024. [arxiv](https://arxiv.org/abs/2402.03271)

**On the Universal Truthfulness Hyperplane Inside LLMs**  
Junteng Liu, Shiqi Chen, Yu Cheng, *<ins>Junxian He</ins>*  
EMNLP 2024. [arxiv](https://arxiv.org/abs/2407.08582)

**Belief Revision: The Adaptability of Large Language Models Reasoning**  
Bryan Wilie, Samuel Cahyawijaya, Etsuko Ishii, *<ins>Junxian He</ins>* , Pascale Fung  
EMNLP 2024. -->





<!-- **Prompt Optimization via Adversarial In-Context Learning**  
Xuan Long Do\*, Yiran Zhao\*, Hannah Brown\*, Yuxi Xie, James Xu Zhao, Nancy F. Chen, Kenji Kawaguchi, Michael Qizhe Xie, *<ins>Junxian He</ins>*  
ACL 2024. [arxiv](https://arxiv.org/abs/2312.02614)

**In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation**  
Shiqi Chen\*, Miao Xiong\*, Junteng Liu, Zhengxuan Wu, Teng Xiao, Siyang Gao, *<ins>Junxian He</ins>*  
ICML 2024. [arxiv](https://arxiv.org/abs/2403.01548) [code](https://github.com/hkust-nlp/Activation_decoding) -->



<!-- **Can LLMs Express Their Uncertainty? An Empirical Evaluation of Confidence Elicitation in LLMs**  
Miao Xiong, Zhiyuan Hu, Xinyang Lu, Yifei Li, Jie Fu, *<ins>Junxian He</ins>*, Bryan Hooi  
ICLR 2024. [arxiv](https://arxiv.org/abs/2306.13063)

**K2: A Foundation Language Model for Geoscience Knowledge Understanding and Utilization**  
Cheng Deng, Tianhang Zhang, Zhongmou He, Yi Xu, Qiyuan Chen, Yuanyuan Shi, Luoyi Fu, Weinan Zhang, Xinbing Wang, Chenghu Zhou, Zhouhan Lin, *<ins>Junxian He</ins>*  
WSDM 2024. [arxiv](https://arxiv.org/abs/2306.05064) [github](https://github.com/davendw49/k2)

**Composing Parameter-Efficient Modules with Arithmetic Operations**  
Jinghan Zhang, Shiqi Chen, Junteng Liu, *<ins>Junxian He</ins>*  
NeurIPS 2023. [arxiv](https://arxiv.org/abs/2306.14870) [code](https://github.com/hkust-nlp/PEM_composition)

**Decomposition Enhances Reasoning via Self-Evaluation Guided Decoding**  
Yuxi Xie, Kenji Kawaguchi, Yiran Zhao, Xu Zhao, Min-Yen Kan, *<ins>Junxian He</ins>*, Qizhe Xie  
NeurIPS 2023. [arxiv](https://arxiv.org/abs/2305.00633) [code](https://github.com/YuxiXie/SelfEval-Guided-Decoding)



**Contrastive Learning of Sentence Embeddings from Scratch**  
Junlei Zhang, Zhenzhong Lan, *<ins>Junxian He</ins>*  
EMNLP 2023. [arxiv](https://arxiv.org/abs/2305.15077)  [code](https://github.com/hkust-nlp/SynCSE)

**Simple Temporal Adaptation to Changing Label Sets: Hashtag Prediction via Dense KNN**  
Fatemehsadat Mireshghallah, Nikolai Vogler, *<ins>Junxian He</ins>*, Omar Florez, Ahmed El-Kishky, Taylor Berg-Kirkpatrick  
EMNLP 2023. [arxiv](https://arxiv.org/abs/2209.05706)

**Automatic Model Selection with Large Language Models for Reasoning**  
Xu Zhao, Yuxi Xie, Kenji Kawaguchi, *<ins>Junxian He</ins>*, Qizhe Xie  
EMNLP 2023 Findings. [arxiv](https://arxiv.org/abs/2305.14333) [code](https://github.com/XuZhao0/Model-Selection-Reasoning)

**Mega: Moving Average Equipped Gated Attention**  
Xuezhe Ma\*, Chunting Zhou\*, Xiang Kong, *<ins>Junxian He</ins>*, Liangke Gui, Graham Neubig, Jonathan May, Luke Zettlemoyer  
ICLR 2023. [arxiv](https://arxiv.org/abs/2209.10655)



**Prompt Consistency for Zero-Shot Task Generalization**  
Chunting Zhou\*, *<ins>Junxian He</ins>*\*, Xuezhe Ma, Taylor Berg-Kirkpatrick, Graham Neubig  
EMNLP 2022 Findings. [arxiv](https://arxiv.org/abs/2205.00049)

**Towards a Unified View of Parameter-Efficient Transfer Learning**  
*<ins>Junxian He</ins>*\*, Chunting Zhou*, Xuezhe Ma, Taylor Berg-Kirkpatrick, Graham Neubig   
ICLR 2022. <span style="color:red"><i>Spotlight</i></span> [OpenReview](https://openreview.net/forum?id=0RDcd5Axok) [arxiv](http://arxiv.org/abs/2110.04366) [code](https://github.com/jxhe/unify-parameter-efficient-tuning)

**Capturing Structural Locality in Non-parametric Language Models**  
Frank F. Xu, *<ins>Junxian He</ins>*, Graham Neubig, Vincent Josua Hellendoorn  
ICLR 2022. [arxiv](https://arxiv.org/abs/2110.02870)

**Neuro-Symbolic Language Modeling with Automaton-augmented Retrieval**  
Uri Alon, Frank F. Xu, *<ins>Junxian He</ins>*, Sudipta Sengupta, Dan Roth, Graham Neubig  
ICML 2022. [arxiv](https://arxiv.org/abs/2201.12431) [code](https://github.com/neulab/retomaton)

**Efficient Nearest Neighbor Language Models**  
*<ins>Junxian He</ins>*, Graham Neubig, Taylor Berg-Kirkpatrick  
EMNLP 2021. [arxiv](https://arxiv.org/abs/2109.04212) [code](https://github.com/jxhe/efficient-knnlm)

**The Source-Target Domain Mismatch Problem in Machine Translation**  
Jiajun Shen, Peng-Jen Chen, Matthew Le, *<ins>Junxian He</ins>*, Jiatao Gu, Myle Ott, Michael Auli, Marc'Aurelio Ranzato  
EACL 2021. [arxiv](https://arxiv.org/abs/1909.13151)

**Dependency Induction Through the Lens of Visual Perception**  
Ruisi Su, Shruti Rijhwani, Hao Zhu, *<ins>Junxian He</ins>*, Xinyu Wang, Yonatan Bisk, Graham Neubig  
CoNLL 2021. [arxiv](https://arxiv.org/abs/2109.09790) [code](https://github.com/ruisi-su/concrete_dep)

**Learning Sparse Protoypes for Text Generation**  
*<ins>Junxian He</ins>*, Taylor Berg-Kirkpatrick, Graham Neubig  
NeurIPS 2020. [arxiv](https://arxiv.org/abs/2006.16336) [code](https://github.com/jxhe/sparse-text-prototype)



**A Probabilistic Formulation of Unsupervised Text Style Transfer**  
*<ins>Junxian He</ins>*\*, Xinyi Wang*, Graham Neubig, Taylor Berg-Kirkpatrick  
ICLR 2020. <span style="color:red"><i>Spotlight</i></span> [arxiv](https://arxiv.org/abs/2002.03912) [code](https://github.com/cindyxinyiwang/deep-latent-sequence-model)

**On the Sentence Embeddings from Pre-trained Language Models**  
Bohan Li, Hao Zhou, *<ins>Junxian He</ins>*, Mingxuan Wang, Yiming Yang, Lei Li  
EMNLP 2020. [arxiv](https://arxiv.org/abs/2011.05864) [code](https://github.com/bohanli/BERT-flow)

**A Surprisingly Effective Fix for Deep Latent Variable Modeling of Text**  
Bohan Li\*, *<ins>Junxian He</ins>*\*, Graham Neubig, Taylor Berg-Kirkpatrick, Yiming Yang  
EMNLP 2019 (short paper). [arxiv](https://arxiv.org/abs/1909.00868) [code](https://github.com/bohanli/vae-pretraining-encoder)

**Cross-Lingual Syntactic Transfer through Unsupervised Adaptation of Invertible Projections**  
*<ins>Junxian He</ins>*, Zhisong Zhang, Taylor Berg-Kirkpatrick, Graham Neubig  
ACL 2019. [arxiv](https://arxiv.org/abs/1906.02656) [code](https://github.com/jxhe/cross-lingual-struct-flow)

**Texar: A modularized, versatile, and extensible toolkit for text generation**  
Zhiting Hu, Haoran Shi, Bowen Tan, Wentao Wang, Zichao Yang, Tiancheng Zhao, *<ins>Junxian He</ins>*, Lianhui Qin, Di Wang, Xuezhe Ma, Zhengzhong Liu, Xiaodan Liang, Wangrong Zhu, Devendra Singh Sachan, Eric P. Xing  
ACL 2019 (demo paper). <span style="color:red">Best demo paper nomination</span>. [arxiv](https://arxiv.org/abs/1809.00794) [GitHub](https://github.com/asyml/texar)





**StructVAE: Tree-structured Latent Variable Models for Semi-supervised Semantic Parsing**  
Pengcheng Yin, Chunting Zhou, *<ins>Junxian He</ins>*, Graham Neubig  
ACL 2018. [arxiv](https://arxiv.org/abs/1806.07832)

**Efficient Correlated Topic Modeling with Topic Embedding**  
*<ins>Junxian He</ins>*\*, Zhiting Hu*, Taylor Berg-Kirkpatrick, Ying Huang, Eric Xing  
KDD 2017. [arxiv](https://arxiv.org/abs/1707.00206)

**Text Network Exploration via Heterogeneous Web of Topics**  
*<ins>Junxian He</ins>*, Ying Huang, Changfeng Liu, Jiaming Shen, Yuting Jia, Xinbing Wang  
ICDM 2016 WorkShop. [arxiv](https://arxiv.org/abs/1610.00219) [demo]({{ site.baseurl }}/demo/TopicAtlas/CiteseerX.html)  -->
